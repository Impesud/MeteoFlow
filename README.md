# MeteoFlow

**Piattaforma ETL containerizzata per dati meteorologici orari**\
Estrae, carica e aggrega dati meteo orari in PostgreSQL/PostGIS, orchestrando tutto con Apache Airflow.

---

## ðŸ“‚ Struttura del repository

```
.
â”œâ”€â”€ db/
â”‚   â””â”€â”€ init.sql              # DDL tabelle + abilitazione PostGIS
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ meteo_etl_dag.py      # Definizione DAG Airflow
â”‚   â””â”€â”€ sql/
â”‚       â””â”€â”€ post_load.sql     # SQL postâ€‘elaborazione
â”œâ”€â”€ data/                     # Dati di input/output
â”‚   â”œâ”€â”€ meteo-jsonl/          # File grezzi raw: meteo (JSON/GZ)
â”‚   â”œâ”€â”€ cities.csv            # cittÃ  (CSV)
â”‚   â”œâ”€â”€ provinces.jsonl       # province (JSONL)
â”‚   â”œâ”€â”€ regions.jsonl         # regioni (JSONL)
â”‚   â””â”€â”€ output/          # File elaborati: aggregazioni (CSV/JSON)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ extract.py
â”‚       â”œâ”€â”€ bulk_copy.py
â”‚       â”œâ”€â”€ load_dimensions.py
â”‚       â”œâ”€â”€ aggregate_sql.py
â”‚       â””â”€â”€ utils/data_utils.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py           # Setup DB per pytest
â”‚   â”œâ”€â”€ test_extract.py
â”‚   â”œâ”€â”€ test_data_utils.py
â”‚   â””â”€â”€ test_aggregate_sql.py
â”œâ”€â”€ .env.example              # Template variabili ambiente
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile                # Custom Airflow image
â”œâ”€â”€ docker-compose.yml        # Servizi: postgres, airflow
â”œâ”€â”€ Makefile                  # Alias: dockerâ€‘up, lint, testâ€¦
â”œâ”€â”€ pyproject.toml            # Configurazione Black, Flake8, Mypy, Bandit
â”œâ”€â”€ .pre-commit-config.yaml   # Hook preâ€‘commit
â””â”€â”€ README.md                 # (questo file)
```

---

## âš™ï¸ Prerequisiti

- **Docker** â‰¥â€¯20.10
- **Docker Compose** â‰¥â€¯1.29
- (facoltativo) `make` su host per alias comodi

---

## ðŸš€ Installazione & Avvio

1. **Clona** il repository:

   ```bash
   git clone git@github.com:Impesud/MeteoFlow.git
   cd MeteoFlow
   ```

2. **Rinomina** il file delle variabili dâ€™ambiente:

   ```bash
   Rinomina .env.example a .env
   ```

3. **Imposta** i permessi per entrypoint.sh, logs/ e data/output:

   ```bash
   chmod +x entrypoint.sh
   chmod 777 logs
   chmod 777 data/output
   ```

4. **Avvia i container**:

   ```bash
   docker-compose up --build
   ```

   - **Postgres+PostGIS** sarÃ  disponibile su `localhost:5432`
   - **Airflow Web UI** su `http://localhost:8080` (user/password: `meteoflow/meteoflow`)

5. **Verifica e Avvio DAG**

   - In Airflow UI il DAG meteo_etl_dag dovrebbe comparire.
   - Il database deve contenere lo schema creato da `db/init.sql`.
   - Lanciare manualmente l'intero DAG dal pulsante "Trigger DAG" presente nell'interfaccia di Airflow UI.
   - In alternativa, dal container si puÃ² lanciare il comando:
    ```bash
   airflow dags trigger meteo_etl_dag â€”conf
    ```

---

## Avvio manuale

### 1ï¸âƒ£ Avvia i container (Postgres+PostGIS e Airflow)
docker-compose up -d --build

### 2ï¸âƒ£ Entra nel container Airflow
docker-compose exec airflow bash

### 3ï¸âƒ£ Carica lo schema iniziale con init.sql
psql -h postgres -U meteo_user -d meteo_db \
  -f /docker-entrypoint-initdb.d/init.sql

### 4ï¸âƒ£ Estrai e prepara i CSV orari
python /opt/airflow/src/scripts/extract.py

### 5ï¸âƒ£ Carica le dimensioni (cities, provinces, regions)
python /opt/airflow/src/scripts/load_dimensions.py

### 6ï¸âƒ£ Applica post_load.sql (geom e region_istat)
psql -h postgres -U meteo_user -d meteo_db \
  -f /opt/airflow/dags/sql/post_load.sql

### 7ï¸âƒ£ (Opzionale) Verifica staging table e vincolo UNIQUE
psql -h postgres -U meteo_user -d meteo_db -c "\d weather_city_hourly_tmp"
psql -h postgres -U meteo_user -d meteo_db -c "\d weather_city_hourly"

### 8ï¸âƒ£ Bulkâ€load + UPSERT in weather_city_hourly
python /opt/airflow/src/scripts/bulk_copy.py

### 9ï¸âƒ£ Aggregazioni per scope
python /opt/airflow/src/scripts/aggregate_sql.py --scope city
python /opt/airflow/src/scripts/aggregate_sql.py --scope prov
python /opt/airflow/src/scripts/aggregate_sql.py --scope reg

### ðŸ”Ÿ Verifica aggregazioni giornaliere cittÃ  (esempio)
psql -h postgres -U meteo_user -d meteo_db \
  -c "SELECT date, COUNT(*) FROM weather_city_daily GROUP BY date ORDER BY date LIMIT 5;"

### 1ï¸âƒ£1ï¸âƒ£ Esci dal container
exit

---

## ðŸ› ï¸ Comandi utili (Makefile)

```bash
make docker-up       # docker-compose up -d --build
make docker-down     # docker-compose down
make lint            # black --check, isort --check, flake8
make types           # mypy src/ tests/
make security        # bandit -r src/
make test            # pytest
make all             # esegue tutti i comandi di controllo codice
```

> Per entrare nella shell del container Airflow:
>
> ```bash
> docker-compose exec airflow bash
> ```

> Per accedere al database Postgres dal container:
>
> ```bash
> docker-compose exec postgres psql -U meteo_user -d meteo_db
> ```

---

## ðŸ”„ Flusso ETL

1. **db/init.sql**
   - Crea lo schema del database: tabelle, indici, vincoli.
   - Abilita lâ€™estensione PostGIS (`CREATE EXTENSION IF NOT EXISTS postgis;`).
   - Definisce le tabelle di dimensione (`cities`, `provinces`, `regions`) e la staging table `weather_city_hourly_tmp`.
   - Aggiunge il vincolo UNIQUE `(istat_code, datetime)` su `weather_city_hourly` per supportare lâ€™upsert.

2. **Airflow DAG** (`dags/meteo_etl_dag.py`)
   - Orchestrazione e scheduling dei task ETL.
   - **extract.py**  
     - Legge file JSONL / `.jsonl.gz`.
     - Usa `orjson.loads` per parsing veloce e gestisce malformazioni **rowâ€‘byâ€‘row** con logging di errori.  
     - Normalizza i record (`clean_dataframe`, `pad_istat_code`) e scrive in batch molto grandi per minimizzare I/O.  
   - **load_dimensions.py**  
     - Popola le tabelle di lookup:  
       - `cities` da CSV (codice ISTAT, lat/lon, nome).  
       - `provinces` da JSON (codice ISTAT, confini).  
       - `regions` da JSON (codice ISTAT, confini).
   - **dags/sql/post_load.sql**  
     - Trasforma i confini testuali (`â€¦_boundaries` WKT) in vere geometrie PostGIS (`geom MULTIPOLYGON`). 
     - Aggiunge la colonna `province_istat` in `cities` e la popola con uno spatialâ€‘join.
     - Aggiunge la colonna `region_istat` in `cities` e la popola con uno spatialâ€‘join.
   - **bulk_copy.py**  
     - Costruisce un CSV temporaneo con solo le colonne necessarie (`HOURLY_COLUMNS`).  
     - **Bulkâ€‘loading** via `COPY â€¦ STDIN` in staging table `weather_city_hourly_tmp`.  
     - **Upsert** in `weather_city_hourly` con `INSERT â€¦ ON CONFLICT DO NOTHING`.  
     - Pulisce la staging table (`TRUNCATE`) per il run successivo.
   - **aggregate_sql.py**  
     - Genera dinamicamente query `INSERT â€¦ SELECT` basate su `AGG_CONFIG`.  
     - Esegue aggregazioni **daily**, **weekly**, **monthly** per **city**, **prov**, **reg** in parallelo.

---

## ðŸ§ª Testing

Esegui i primi test dentro al container Airflow:

```bash
docker-compose exec airflow pytest --maxfail=1 --disable-warnings -q
```

---

## ðŸ§ª PerchÃ© questo ETL e quali alternative per un takeâ€‘home test

Per un **takeâ€‘home test** ho scelto unâ€™architettura che:

1. **â€œEndâ€‘toâ€‘endâ€ in un unico ambiente containerizzato**  
   - **Dockerâ€¯Compose** (Postgres+PostGIS + Airflow): zero setup esterno, riproducibilitÃ  immediata con `docker-compose up --build`.  
   - Tutto il codice, gli script e le configurazioni vivono nel repository, nessuna dipendenza nascosta.

2. **SemplicitÃ  operativa e scalabilitÃ  realâ€‘world**  
   - **Python + Pandas + orjson**: parsing rapido di JSONL/GZ, batch size configurabile per processare decine di milioni di righe senza OOM.  
   - **COPY â€¦ STDIN + staging table + UPSERT**: evita migliaia di singole INSERT, garantisce idempotenza e performance native di Postgres.

3. **Basso attrito e massima visibilitÃ **  
   - **PostgreSQL + PostGIS**: supporto outâ€‘ofâ€‘theâ€‘box per dati spaziali e constraint di unicitÃ  (`istat_code, datetime`).  
   - **Apache Airflow**: orchestrazione, retry automatici, logging centralizzato, task grouping, e monitoraggio via UI.

4. **QualitÃ  del codice e operativitÃ **  
   - **Logging strutturato** in ogni script (info, warning, error), report su record malformati e metriche di avanzamento (batch flush, totali).  
   - **Controlli statici e CI**:
     - **Black** & **isort** per formattazione;
     - **Flake8** per linting;
     - **Mypy** per static typing;
     - **Bandit** per security scan;
     - **pytest** con fixture DB dockerâ€‘based per unit/integration test.

---

### Alternative valutate

- **Spark + Parquet**  
  - **Pro**: Parquet Ã¨ molto efficiente in lettura e compressione, ideale per dataset molto grandi.  
  - **Contro**: aggiunge complessitÃ  (cluster Spark, configurazione HDFS/S3), e per il volume di dati di questo test un file CSV singolo in locale Ã¨ sufficiente e piÃ¹ semplice da gestire.  
  - **Quando**: ho adottato Parquet in progetti AI MLOps e AI FinOps in produzione, dove la scalabilitÃ  e lâ€™I/O throughput giustificano lâ€™overhead.

- **Kafka + streaming**  
  - **Pro**: consente ingestione realâ€‘time e processing a bassa latenza.  
  - **Contro**: richiede broker, topic management, consumer groups â€” overkill per un homeâ€‘test batch.  
  - **Quando**: usato in un progetto di previsioni Eâ€‘commerce AI in produzione per pipeline streaming.

- **Materialized Views in Postgres**  
  - **Pro**: mantengono aggregazioni preâ€‘calcolate e indicizzate dentro il database.  
  - **Contro**: servono per scenari di produzione con carichi continui; per un proofâ€‘ofâ€‘concept preferibile generare tabelle dedicate via Airflow.

- **CSV vs Parquet**  
  - Ho scelto CSV perchÃ©:
    - Ã¨ nativamente supportato dal comando `COPY` di Postgres senza dipendenze aggiuntive;
    - Ã¨ immediatamente leggibile e debuggabile con strumenti di linea di comando;
    - il test richiede una soluzione endâ€‘toâ€‘end semplice da avviare via Docker Compose;
  - Parquet rimane unâ€™ottima scelta per dataset >â€¯100â€¯GB o in presenza di query analitiche intensi, ma qui il dataset orario compresso sta sotto soglia e CSV riduce il timeâ€‘toâ€‘value.

---

### Possibili estensioni

- **Partitioning** delle tabelle orarie (range su `datetime`) per scansioni piÃ¹ veloci.
- **Parametrizzazione DAG**: aggiungere sensori sui file, alert su fallimenti e SLA.
- **Data quality** con Great Expectations per validare record in ingresso. Applicato su progetti AI MLOps e AI FinOps in staging e produzione.
- **Caching/API layer** (FastAPI + Redis) per servire i dati aggregati in <100â€¯ms. Applicato su progetti AI MLOps e AI FinOps in staging e produzione.

Questa architettura bilancia rapiditÃ  di sviluppo, facilitÃ  di review e soliditÃ  per dataset medioâ€‘grandi: ideale per un takeâ€‘home test. 

---

# Validazione End-to-End SQL

## 1. Esecuzione manuale

1. Entra nel container Airflow:

   ```bash
   docker-compose exec airflow bash
   ```

2. Da lÃ¬ lancia psql sul service Postgres:

   ```bash
   psql -h postgres -U meteo_user -d meteo_db
   ```
   Pass: meteo_pass

3. Ora puoi caricare i tuoi SQL, ad esempio:

   ```bash
   \i /opt/airflow/tests/sql/count_city_daily.sql
   ```

   - Se la query termina senza errori e restituisce il numero di righe atteso, significa che lâ€™aggregazione giornaliera per cittÃ  esiste.

## 2. Panoramica delle query di validazione

| File                                   | Scopo                                                                  |
|----------------------------------------|------------------------------------------------------------------------|
| **count_city_daily.sql**               | Verifica aggregazioni giornaliere per cittÃ                             |
| **check_null_keys.sql**                | Controlla che non ci siano chiavi ISTAT nulle                          |
| **top_precipitation_cities.sql**       | Elenca le 5 cittÃ  con piÃ¹ precipitazione nellâ€™ultimo giorno            |
| **spatial_join_cities_regions.sql**    | Assicura che ogni cittÃ  abbia una regione assegnata                    |
| **check_province_geometry.sql**        | Verifica che tutte le province abbiano la geometria `geom`            |
| **check_region_geometry.sql**          | Verifica che tutte le regioni abbiano la geometria `geom`              |
| **rolling_avg_temp_city.sql**          | Calcola media mobile a 7 giorni di temperatura per una cittÃ            |
| **weekly_precip_change_province.sql**  | Confronta precipitazione tra ultime due settimane e calcola % change   |
| **check_hourly_counts.sql**            | Verifica che ogni giorno ci siano esattamente 24 record orari          |
| **temp_trend_correlation_city.sql**    | Calcola coefficiente di correlazione tra data (epoch) e temperatura    |
| **temp_anomaly_detection_city.sql**    | Rileva anomalie termiche con Zâ€‘score > 2 su finestra mobile di 30 giorni |    


## ðŸ“œ Licenza

MIT Â© Erick Jara
