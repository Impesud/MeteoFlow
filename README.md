# MeteoFlow

**Piattaforma ETL containerizzata per dati meteorologici orari**\
Estrae, carica e aggrega dati meteo orari in PostgreSQL/PostGIS, orchestrando tutto con Apache Airflow.

---

## üìÇ Struttura del repository

```
.
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îî‚îÄ‚îÄ init.sql              # DDL tabelle + abilitazione PostGIS
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ meteo_etl_dag.py      # Definizione DAG Airflow
‚îÇ   ‚îî‚îÄ‚îÄ sql/
‚îÇ       ‚îî‚îÄ‚îÄ post_load.sql     # SQL post‚Äëelaborazione
‚îú‚îÄ‚îÄ data/                     # Dati di input/output
‚îÇ   ‚îú‚îÄ‚îÄ meteo-jsonl/          # File grezzi raw: meteo (JSON/GZ)
‚îÇ   ‚îú‚îÄ‚îÄ cities.csv            # citt√† (CSV)
‚îÇ   ‚îú‚îÄ‚îÄ provinces.jsonl       # province (JSONL)
‚îÇ   ‚îú‚îÄ‚îÄ regions.jsonl         # regioni (JSONL)
‚îÇ   ‚îî‚îÄ‚îÄ output/          # File elaborati: aggregazioni (CSV/JSON)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ extract.py
‚îÇ       ‚îú‚îÄ‚îÄ bulk_copy.py
‚îÇ       ‚îú‚îÄ‚îÄ load_dimensions.py
‚îÇ       ‚îú‚îÄ‚îÄ aggregate_sql.py
‚îÇ       ‚îî‚îÄ‚îÄ utils/data_utils.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py           # Setup DB per pytest
‚îÇ   ‚îú‚îÄ‚îÄ test_extract.py
‚îÇ   ‚îú‚îÄ‚îÄ test_data_utils.py
‚îÇ   ‚îî‚îÄ‚îÄ test_aggregate_sql.py
‚îú‚îÄ‚îÄ .env.example              # Template variabili ambiente
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ Dockerfile                # Custom Airflow image
‚îú‚îÄ‚îÄ docker-compose.yml        # Servizi: postgres, airflow
‚îú‚îÄ‚îÄ Makefile                  # Alias: docker‚Äëup, lint, test‚Ä¶
‚îú‚îÄ‚îÄ pyproject.toml            # Configurazione Black, Flake8, Mypy, Bandit
‚îú‚îÄ‚îÄ .pre-commit-config.yaml   # Hook pre‚Äëcommit
‚îî‚îÄ‚îÄ README.md                 # (questo file)
```

---

## ‚öôÔ∏è Prerequisiti

- **Docker** ‚â•‚ÄØ20.10
- **Docker Compose** ‚â•‚ÄØ1.29
- (facoltativo) `make` su host per alias comodi

---

## üöÄ Installazione & Avvio

1. **Clona** il repository:

   ```bash
   git clone git@github.com:Impesud/MeteoFlow.git
   cd MeteoFlow
   ```

2. **Rinomina** il file delle variabili d‚Äôambiente:

   ```bash
   Rinomina .env.example a .env
   ```

3. **Imposta** i permessi per entrypoint.sh, logs/ e data/output:

   ```bash
   chmod +x entrypoint.sh
   chmod 777 logs
   chmod 777 data/output
   ```

4. **Avvia i container**:

   ```bash
   docker-compose up --build
   ```

   - **Postgres+PostGIS** sar√† disponibile su `localhost:5432`
   - **Airflow Web UI** su `http://localhost:8080` (user/password: `meteoflow/meteoflow`)

5. **Verifica e Avvio DAG**

   - In Airflow UI il DAG meteo_etl_dag dovrebbe comparire.
   - Il database deve contenere lo schema creato da `db/init.sql`.
   - Lanciare manualmente l'intero DAG dal pulsante "Trigger DAG" presente nell'interfaccia di Airflow UI.
   - In alternativa, dal container si pu√≤ lanciare il comando:
    ```bash
   airflow dags trigger meteo_etl_dag ‚Äîconf
    ```

---

## Avvio manuale

### 1Ô∏è‚É£ Avvia i container (Postgres+PostGIS e Airflow)
docker-compose up -d --build

### 2Ô∏è‚É£ Entra nel container Airflow
docker-compose exec airflow bash

### 3Ô∏è‚É£ Carica lo schema iniziale con init.sql
psql -h postgres -U meteo_user -d meteo_db \
  -f /docker-entrypoint-initdb.d/init.sql

### 4Ô∏è‚É£ Estrai e prepara i CSV orari
python /opt/airflow/src/scripts/extract.py

### 5Ô∏è‚É£ Carica le dimensioni (cities, provinces, regions)
python /opt/airflow/src/scripts/load_dimensions.py

### 6Ô∏è‚É£ Applica post_load.sql (geom e region_istat)
psql -h postgres -U meteo_user -d meteo_db \
  -f /opt/airflow/dags/sql/post_load.sql

### 7Ô∏è‚É£ (Opzionale) Verifica staging table e vincolo UNIQUE
psql -h postgres -U meteo_user -d meteo_db -c "\d weather_city_hourly_tmp"
psql -h postgres -U meteo_user -d meteo_db -c "\d weather_city_hourly"

### 8Ô∏è‚É£ Bulk‚Äêload + UPSERT in weather_city_hourly
python /opt/airflow/src/scripts/bulk_copy.py

### 9Ô∏è‚É£ Aggregazioni per scope
python /opt/airflow/src/scripts/aggregate_sql.py --scope city
python /opt/airflow/src/scripts/aggregate_sql.py --scope prov
python /opt/airflow/src/scripts/aggregate_sql.py --scope reg

### üîü Verifica aggregazioni giornaliere citt√† (esempio)
psql -h postgres -U meteo_user -d meteo_db \
  -c "SELECT date, COUNT(*) FROM weather_city_daily GROUP BY date ORDER BY date LIMIT 5;"

### 1Ô∏è‚É£1Ô∏è‚É£ Esci dal container
exit

---

## üõ†Ô∏è Comandi utili (Makefile)

```bash
make docker-up       # docker-compose up -d --build
make docker-down     # docker-compose down
make lint            # black --check, isort --check, flake8
make types           # mypy src/ tests/
make security        # bandit -r src/
make test            # pytest
make all             # esegue tutti i comandi di controllo codice
```

> Per entrare nella shell del container Airflow:
>
> ```bash
> docker-compose exec airflow bash
> ```

> Per accedere al database Postgres dal container:
>
> ```bash
> docker-compose exec postgres psql -U meteo_user -d meteo_db
> ```

---

## üîÑ Flusso ETL

1. **db/init.sql**
   - Crea lo schema del database: tabelle, indici, vincoli.
   - Abilita l‚Äôestensione PostGIS (`CREATE EXTENSION IF NOT EXISTS postgis;`).
   - Definisce le tabelle di dimensione (`cities`, `provinces`, `regions`) e la staging table `weather_city_hourly_tmp`.
   - Aggiunge il vincolo UNIQUE `(istat_code, datetime)` su `weather_city_hourly` per supportare l‚Äôupsert.

2. **Airflow DAG** (`dags/meteo_etl_dag.py`)
   - Orchestrazione e scheduling dei task ETL.
   - **extract.py**  
     - Legge file JSONL / `.jsonl.gz`.
     - Usa `orjson.loads` per parsing veloce e gestisce malformazioni **row‚Äëby‚Äërow** con logging di errori.  
     - Normalizza i record (`clean_dataframe`, `pad_istat_code`) e scrive in batch molto grandi per minimizzare I/O.  
   - **load_dimensions.py**  
     - Popola le tabelle di lookup:  
       - `cities` da CSV (codice ISTAT, lat/lon, nome).  
       - `provinces` da JSON (codice ISTAT, confini).  
       - `regions` da JSON (codice ISTAT, confini).
   - **dags/sql/post_load.sql**  
     - Trasforma i confini testuali (`‚Ä¶_boundaries` WKT) in vere geometrie PostGIS (`geom MULTIPOLYGON`). 
     - Aggiunge la colonna `province_istat` in `cities` e la popola con uno spatial‚Äëjoin.
     - Aggiunge la colonna `region_istat` in `cities` e la popola con uno spatial‚Äëjoin.
   - **bulk_copy.py**  
     - Costruisce un CSV temporaneo con solo le colonne necessarie (`HOURLY_COLUMNS`).  
     - **Bulk‚Äëloading** via `COPY ‚Ä¶ STDIN` in staging table `weather_city_hourly_tmp`.  
     - **Upsert** in `weather_city_hourly` con `INSERT ‚Ä¶ ON CONFLICT DO NOTHING`.  
     - Pulisce la staging table (`TRUNCATE`) per il run successivo.
   - **aggregate_sql.py**  
     - Genera dinamicamente query `INSERT ‚Ä¶ SELECT` basate su `AGG_CONFIG`.  
     - Esegue aggregazioni **daily**, **weekly**, **monthly** per **city**, **prov**, **reg** in parallelo.

---

## üß™ Testing

Esegui i primi test dentro al container Airflow:

```bash
docker-compose exec airflow pytest --maxfail=1 --disable-warnings -q
```

---

## üß™ Perch√© questo ETL e quali alternative per un take‚Äëhome test

Per un **take‚Äëhome test** ho scelto un‚Äôarchitettura che:

1. **‚ÄúEnd‚Äëto‚Äëend‚Äù in un unico ambiente containerizzato**  
   - **Docker‚ÄØCompose** (Postgres+PostGIS + Airflow): zero setup esterno, riproducibilit√† immediata con `docker-compose up --build`.  
   - Tutto il codice, gli script e le configurazioni vivono nel repository, nessuna dipendenza nascosta.

2. **Semplicit√† operativa e scalabilit√† real‚Äëworld**  
   - **Python + Pandas + orjson**: parsing rapido di JSONL/GZ, batch size configurabile per processare decine di milioni di righe senza OOM.  
   - **COPY ‚Ä¶ STDIN + staging table + UPSERT**: evita migliaia di singole INSERT, garantisce idempotenza e performance native di Postgres.

3. **Basso attrito e massima visibilit√†**  
   - **PostgreSQL + PostGIS**: supporto out‚Äëof‚Äëthe‚Äëbox per dati spaziali e constraint di unicit√† (`istat_code, datetime`).  
   - **Apache Airflow**: orchestrazione, retry automatici, logging centralizzato, task grouping, e monitoraggio via UI.

4. **Qualit√† del codice e operativit√†**  
   - **Logging strutturato** in ogni script (info, warning, error), report su record malformati e metriche di avanzamento (batch flush, totali).  
   - **Controlli statici e CI**:
     - **Black** & **isort** per formattazione;
     - **Flake8** per linting;
     - **Mypy** per static typing;
     - **Bandit** per security scan;
     - **pytest** con fixture DB docker‚Äëbased per unit/integration test.

---

### Alternative valutate

- **Spark + Parquet**  
  - **Pro**: Parquet √® molto efficiente in lettura e compressione, ideale per dataset molto grandi.  
  - **Contro**: aggiunge complessit√† (cluster Spark, configurazione HDFS/S3), e per il volume di dati di questo test un file CSV singolo in locale √® sufficiente e pi√π semplice da gestire.  
  - **Quando**: ho adottato Parquet in progetti AI MLOps e AI FinOps in produzione, dove la scalabilit√† e l‚ÄôI/O throughput giustificano l‚Äôoverhead.

- **Kafka + streaming**  
  - **Pro**: consente ingestione real‚Äëtime e processing a bassa latenza.  
  - **Contro**: richiede broker, topic management, consumer groups ‚Äî overkill per un home‚Äëtest batch.  
  - **Quando**: usato in un progetto di previsioni E‚Äëcommerce AI in produzione per pipeline streaming.

- **Materialized Views in Postgres**  
  - **Pro**: mantengono aggregazioni pre‚Äëcalcolate e indicizzate dentro il database.  
  - **Contro**: servono per scenari di produzione con carichi continui; per un proof‚Äëof‚Äëconcept preferibile generare tabelle dedicate via Airflow.

- **CSV vs Parquet**  
  - Ho scelto CSV perch√©:
    - √® nativamente supportato dal comando `COPY` di Postgres senza dipendenze aggiuntive;
    - √® immediatamente leggibile e debuggabile con strumenti di linea di comando;
    - il test richiede una soluzione end‚Äëto‚Äëend semplice da avviare via Docker Compose;
  - Parquet rimane un‚Äôottima scelta per dataset >‚ÄØ100‚ÄØGB o in presenza di query analitiche intensi, ma qui il dataset orario compresso sta sotto soglia e CSV riduce il time‚Äëto‚Äëvalue.

---

### Possibili estensioni

- **Partitioning** delle tabelle orarie (range su `datetime`) per scansioni pi√π veloci.
- **Parametrizzazione DAG**: aggiungere sensori sui file, alert su fallimenti e SLA.
- **Data quality** con Great Expectations per validare record in ingresso. Applicato su progetti AI MLOps e AI FinOps in staging e produzione.
- **Caching/API layer** (FastAPI + Redis) per servire i dati aggregati in <100‚ÄØms. Applicato su progetti AI MLOps e AI FinOps in staging e produzione.

Questa architettura bilancia rapidit√† di sviluppo, facilit√† di review e solidit√† per dataset medio‚Äëgrandi: ideale per un take‚Äëhome test. 

---

# Validazione End-to-End SQL

## 1. Esecuzione manuale

1. Entra nel container Airflow:

   ```bash
   docker-compose exec airflow bash
   ```

2. Da l√¨ lancia psql sul service Postgres:

   ```bash
   psql -h postgres -U meteo_user -d meteo_db
   ```
   Pass: meteo_pass

3. Ora puoi caricare i tuoi SQL, ad esempio:

   ```bash
   \i /opt/airflow/tests/sql/count_city_daily.sql
   ```

   - Se la query termina senza errori e restituisce il numero di righe atteso, significa che l‚Äôaggregazione giornaliera per citt√† esiste.

## 2. Panoramica delle query di validazione

| File                                   | Scopo                                                                  |
|----------------------------------------|------------------------------------------------------------------------|
| **count_city_daily.sql**               | Verifica aggregazioni giornaliere per citt√†                            |
| **check_null_keys.sql**                | Controlla che non ci siano chiavi ISTAT nulle                          |
| **top_precipitation_cities.sql**       | Elenca le 5 citt√† con pi√π precipitazione nell‚Äôultimo giorno            |
| **spatial_join_cities_regions.sql**    | Assicura che ogni citt√† abbia una regione assegnata                    |
| **check_province_geometry.sql**        | Verifica che tutte le province abbiano la geometria `geom`            |
| **check_region_geometry.sql**          | Verifica che tutte le regioni abbiano la geometria `geom`              |
| **rolling_avg_temp_city.sql**          | Calcola media mobile a 7 giorni di temperatura per una citt√†           |
| **weekly_precip_change_province.sql**  | Confronta precipitazione tra ultime due settimane e calcola % change   |
| **check_hourly_counts.sql**            | Verifica che ogni giorno ci siano esattamente 24 record orari          |
| **temp_trend_correlation_city.sql**    | Calcola coefficiente di correlazione tra data (epoch) e temperatura    |
| **temp_anomaly_detection_city.sql**    | Rileva anomalie termiche con Z‚Äëscore > 2 su finestra mobile di 30 giorni |    


## üìú Licenza

MIT ¬© Erick Jara
